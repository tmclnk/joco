{"id":"joco-0zx","title":"B3: Re-train A5 (Enhanced TF-IDF) on extended dataset","description":"Re-train A5 (Enhanced TF-IDF with feat/fix features) on extended dataset.\n\nOriginal A5 results (261 train, 29 val):\n- Validation accuracy: 65.5%\n- feat precision: 50.0% (up from A1's 31%)\n- fix precision: 66.7% (up from A1's 36%)\n- Trade-off: -10.4pp overall accuracy for better feat/fix\n\nExtended dataset benefits:\n- 4x more examples (1,276 vs 261)\n- More feat/fix examples to learn from\n- Better feature signal-to-noise ratio\n\nExpected improvements:\n- Validation accuracy: 75-80% (should match or beat A1 now)\n- feat precision: \u003e60%\n- fix precision: \u003e70%\n- No trade-off between overall accuracy and feat/fix precision\n\nApproach:\n1. Load extended dataset\n2. Use same 13 enhanced features from A5\n3. Train and evaluate\n4. Compare to original A5 and new B2 results\n5. Verify feat/fix improvements persist with more data\n6. Log results to EXPERIMENT_LOG.md\n\nThis is HIGH PRIORITY - A5's features are good but needed more data.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:23:25.45206447Z","created_by":"Claude Code","updated_at":"2026-01-18T20:29:37.213302347Z","closed_at":"2026-01-18T20:29:37.213305013Z","comments":[{"id":2,"issue_id":"joco-0zx","author":"Claude Code","text":"COMPLETED: B3 experiment finished with UNEXPECTED results.\n\n**Results:**\n- Validation accuracy: 59.6% (vs expected 75-80%) ❌\n- Feat precision: 36.8% (vs expected \u003e60%) ❌\n- Fix precision: 74.2% (vs expected \u003e70%) ✓\n- Angular benchmark: 51.0%\n\n**Key Finding:** HYPOTHESIS REJECTED\n- Extended dataset HURT performance (65.5% → 59.6%)\n- A5's 13 enhanced features don't generalize to larger, more diverse datasets\n- Original A5 results were due to overfitting on small validation set (29 examples)\n- Keyword-based features have high overlap (\"add\" appears in both feat and fix)\n\n**Conclusion:**\n- A5 approach is NOT viable for production\n- Classical ML approaches plateau at ~60% accuracy on extended data\n- Need semantic understanding (embeddings/LLMs) for feat/fix distinction\n- Documented results in EXPERIMENT_LOG.md under B3\n\n**Files Created:**\n- scripts/b3_a5_extended.py (752 lines)\n- Full results logged in EXPERIMENT_LOG.md","created_at":"2026-01-18T20:30:03Z"}]}
{"id":"joco-14l","title":"C3: Apply anti-overfitting measures to structural feature classifier","description":"Enhance C2 classifier with proper anti-overfitting techniques.\n\nDEPENDS ON: C2 must be complete first\n\nCurrent problem: All experiments showed severe overfitting:\n- A1: +11% train-val gap\n- A2: +24.5% gap  \n- A3: +26.8% gap\n- A4: +9-19% gap\n- B2/B3/B4: All overfitted on extended data\n\nAnti-overfitting measures to implement:\n\n1. K-FOLD CROSS-VALIDATION (CRITICAL):\n   - Use 5-fold StratifiedKFold\n   - Report mean ± std accuracy\n   - Ensures robust estimates\n   - Every example used for validation\n\n2. STRONGER REGULARIZATION:\n   - LogisticRegression with C=0.1 (vs default 1.0)\n   - Try L1 penalty for feature selection\n   - Prevents memorization\n\n3. THREE-WAY SPLIT:\n   - 60% train / 20% validation / 20% test\n   - Test set NEVER touched until final eval\n   - Prevents peeking at validation performance\n\n4. FEATURE SELECTION:\n   - If needed, reduce 15 features to top 10\n   - Use feature importance ranking\n   - Remove weakest signals\n\n5. ENSEMBLE VALIDATION:\n   - Train 5 models (one per fold)\n   - Average predictions\n   - More robust than single model\n\n6. DEPLOYMENT CRITERIA:\n   - Train-val gap \u003c 10%\n   - Val-test gap \u003c 3%\n   - CV std \u003c 5%\n   - Only deploy if criteria met\n\nExpected results:\n- CV: 68-72% ± 3% (low variance)\n- Train-val gap: \u003c8%\n- Robust across different data splits\n- Production-ready classifier\n\nSuccess criteria: Train-val gap \u003c 10% AND val == test accuracy","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:37:06.889508233Z","created_by":"Claude Code","updated_at":"2026-01-18T20:46:58.292916605Z","closed_at":"2026-01-18T20:46:58.292918438Z","dependencies":[{"issue_id":"joco-14l","depends_on_id":"joco-38b","type":"blocks","created_at":"2026-01-18T20:37:19.692636122Z","created_by":"Claude Code"}]}
{"id":"joco-191","title":"Implement generation parameters","description":"Apply maxTokens from config. Apply temperature from config. Set appropriate stop tokens.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:13.362114-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:01:56.166114-06:00","closed_at":"2026-01-13T16:01:56.166114-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-191","depends_on_id":"joco-6m8","type":"depends-on","created_at":"2026-01-13T15:18:21.183098-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-191","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:24.396147-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-25d","title":"Configure Maven dependencies for HTTP client and JSON parsing","description":"Add java.net.http (built-in) and Jackson for JSON. Keep dependencies minimal for fast startup.","status":"closed","priority":0,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:10.642046-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:41:12.20733-06:00","closed_at":"2026-01-13T15:41:12.20733-06:00","close_reason":"Configured Maven dependencies: Added Gson 2.11.0 for JSON parsing (lightweight at 250KB). Using built-in java.net.http for HTTP client (no external dependency). Both choices align with minimal footprint requirement.","dependencies":[{"issue_id":"joco-25d","depends_on_id":"joco-jps","type":"parent-child","created_at":"2026-01-13T15:18:22.734053-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-2gp","title":"A5: Enhanced TF-IDF features specifically for feat vs fix distinction","description":"Improve TF-IDF approach with features targeting feat/fix distinction.\n\nCurrent problem: A1 shows 31% precision for feat, 36% for fix - the biggest weakness.\n\nNew features to add:\n1. Code change patterns:\n   - New file additions (feat signal)\n   - Modified existing files (fix signal)\n   - Insertion/deletion ratio (new code = feat, small fixes = fix)\n   \n2. Diff content keywords:\n   - 'add', 'implement', 'introduce' → feat\n   - 'fix', 'bug', 'issue', 'resolve', 'correct' → fix\n   - 'error', 'exception', 'null', 'crash' → fix\n   - 'feature', 'support', 'enable' → feat\n\n3. Code structure:\n   - New function definitions → feat\n   - Modified function bodies → fix\n   - New imports/dependencies → feat\n\n4. File count features:\n   - Many files changed (5+) → feat (new feature spans multiple files)\n   - 1-2 files changed → fix (targeted bug fix)\n\nApproach:\n- Add these as additional features to TF-IDF vectorizer\n- Retrain LogisticRegression with expanded feature set\n- Target: \u003e50% precision on feat/fix\n\nThis is HIGH PRIORITY as it directly addresses A1's main weakness.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:11:43.955025287Z","created_by":"Claude Code","updated_at":"2026-01-18T20:16:27.221748872Z","closed_at":"2026-01-18T20:16:27.221750788Z"}
{"id":"joco-36r","title":"Add attribution to OpenCommit project","description":"joco is inspired by OpenCommit (https://github.com/di-sukharev/opencommit). Thanks to @di-sukharev and the OpenCommit contributors for creating such a useful tool that inspired this project!","status":"closed","priority":4,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T10:39:58.04376-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T10:49:36.794992-06:00","closed_at":"2026-01-15T10:49:36.794992-06:00","close_reason":"Added Acknowledgments section to README.md with link to OpenCommit repo"}
{"id":"joco-38b","title":"C2: Structural feature classifier for commit type prediction","description":"Implement classifier using code structure features instead of text features.\n\nHYPOTHESIS: Code structure features (file operations, line changes, hunk patterns) are MORE predictive than text features for feat/fix distinction because they're universal across repos.\n\nStructural features to extract (15 total):\n1. File operations: new_files, modified_files, deleted_files\n2. Line changes: insertions, deletions, net_lines, insert_delete_ratio\n3. Hunk analysis: hunk_count, avg_hunk_size, max_hunk_size, min_hunk_size\n4. Derived: lines_per_file, hunks_per_file, fragmentation_score\n5. File types: pct_code_files, pct_docs_files, pct_test_files, pct_config_files\n\nKey advantages:\n- Low dimensional (15 features \u003c\u003c 261 examples)\n- Language/repo independent\n- Directly captures commit intent\n- Less prone to overfitting than 1000-dim TF-IDF\n\nApproach:\n1. Parse git diff output to extract structural metrics\n2. Train LogisticRegression on 15 features\n3. Use ORIGINAL 261 dataset (proven quality)\n4. Compare to B2/B3 text-based approaches\n5. Focus on feat/fix precision (current: 37%)\n\nExpected: \u003e70% feat/fix precision, 65-70% overall accuracy\n\nThis is foundation for C3 anti-overfitting improvements.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:36:47.223638344Z","created_by":"Claude Code","updated_at":"2026-01-18T20:41:37.249720529Z","closed_at":"2026-01-18T20:41:37.249722029Z","comments":[{"id":4,"issue_id":"joco-38b","author":"Claude Code","text":"COMPLETED: C2 structural feature classifier implemented and evaluated.\n\n**Results:**\n- Validation accuracy: 69.0% (vs B2: 56.7%, B3: 59.6%)\n- Training accuracy: 55.9% (NEGATIVE overfitting: -13.0% gap!)\n- Feat precision: 50.0% (vs target 70%)\n- Fix precision: 55.6% (vs target 70%)\n- Docs F1: 0.93 (excellent file type detection)\n\n**Key Achievement:** \nStructural features BEAT text-based TF-IDF by 12.3% on overall accuracy, proving the hypothesis that structural features are more universal and repo-independent.\n\n**Unique Finding:**\nFirst experiment with NEGATIVE overfitting gap (validation \u003e training), suggesting model is underfitting and has room for improvement.\n\n**Files Created:**\n- scripts/c2_structural_features.py (561 lines)\n- Full results logged in EXPERIMENT_LOG.md\n\n**Status:** PARTIAL SUCCESS - accuracy target met (69% \u003e 65%), but feat/fix precision below 70% target. Ready to proceed with C3 anti-overfitting work.","created_at":"2026-01-18T20:41:52Z"}]}
{"id":"joco-39f","title":"D3: Hyperparameter tuning for LoRA fine-tuning","description":"Optimize LoRA hyperparameters to improve fine-tuning performance.\n\nCurrent hyperparameters (from existing model):\n- LoRA rank: 8\n- LoRA alpha: 16\n- Learning rate: 5e-5\n- Batch size: 1\n- Epochs: 1 (original) / 3 (extended)\n\nHyperparameters to tune:\n\n1. LoRA Rank [4, 8, 16, 32]:\n   - Higher rank = more capacity but more overfitting risk\n   - Lower rank = less capacity but better generalization\n   \n2. LoRA Alpha [8, 16, 32]:\n   - Controls scaling of LoRA weights\n   - Ratio to rank matters (alpha/rank)\n   \n3. Learning Rate [1e-5, 5e-5, 1e-4]:\n   - Too high = unstable training\n   - Too low = slow convergence\n   \n4. Epochs [1, 2, 3, 5]:\n   - Monitor validation loss\n   - Use early stopping\n\nApproach:\n1. Start with grid search on rank [8, 16] and alpha [16, 32]\n2. Fix best rank/alpha, tune learning rate\n3. Fix best LR, tune epochs with early stopping\n4. Use extended dataset (1,276 examples)\n5. Evaluate each config on validation set\n6. Report best configuration\n\nSuccess metric: \u003e90/100 score (beat 88/100 baseline)\n\nExpected: Optimal hyperparameters should improve 2-5% over default.","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:48:59.464402288Z","created_by":"Claude Code","updated_at":"2026-01-18T21:47:03.880126737Z","closed_at":"2026-01-18T21:47:03.880126737Z","close_reason":"Abandoned based on D1 findings: existing LoRA model scored 24/100 vs 88/100 multi-step prompt baseline. Multi-step prompting is vastly superior and production-ready. Further fine-tuning experiments not justified given 64-point gap and infrastructure constraints.","dependencies":[{"issue_id":"joco-39f","depends_on_id":"joco-rlc","type":"blocks","created_at":"2026-01-18T20:50:26.10461409Z","created_by":"Claude Code"}]}
{"id":"joco-3c7","title":"D5: Compare fine-tuned model vs multi-step prompting strategy","description":"Determine if fine-tuning beats multi-step prompting or if they should be combined.\n\nCurrent multi-step approach (MultiStepCommitGenerator):\n- Step 1: Classify type (10 tokens max)\n- Step 2: Generate description given type (25 tokens max)\n- Result: 88/100 score, 100% format compliance\n- Advantage: Decomposes problem, forces format\n\nFine-tuned model approach:\n- Single-pass generation\n- Trained on 1,276 examples\n- May memorize format better\n- May be faster (1 query vs 2)\n\nComparison experiments:\n\n1. BASELINE COMPARISON:\n   - Multi-step (current): 88/100 score\n   - Fine-tuned (best from D2/D3): TBD score\n   - Which is better?\n\n2. ENSEMBLE APPROACH:\n   - Fine-tuned generates full message\n   - Multi-step validates/corrects format\n   - Best of both worlds?\n\n3. HYBRID STRATEGY:\n   - Use fine-tuned for common patterns\n   - Fallback to multi-step for edge cases\n   - Optimize for speed + quality\n\nTasks:\n1. Evaluate best fine-tuned model from D2/D3/D4\n2. Compare head-to-head with multi-step on same test set\n3. Test ensemble: fine-tuned + multi-step validation\n4. Measure: quality, speed, format compliance\n5. Recommend production strategy\n\nMetrics:\n- Quality score (0-100)\n- Format compliance (%)\n- Type accuracy (%)\n- Inference time (ms)\n- Token usage (cost)\n\nExpected: Fine-tuned may have better quality but multi-step has better format compliance. Ensemble may be optimal.\n\nHYPOTHESIS: Combination of fine-tuning + multi-step prompting will beat either approach alone.","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:49:37.501619122Z","created_by":"Claude Code","updated_at":"2026-01-18T21:47:03.887908543Z","closed_at":"2026-01-18T21:47:03.887908543Z","close_reason":"Abandoned based on D1 findings: existing LoRA model scored 24/100 vs 88/100 multi-step prompt baseline. Multi-step prompting is vastly superior and production-ready. Further fine-tuning experiments not justified given 64-point gap and infrastructure constraints.","dependencies":[{"issue_id":"joco-3c7","depends_on_id":"joco-39f","type":"blocks","created_at":"2026-01-18T20:50:33.835385412Z","created_by":"Claude Code"},{"issue_id":"joco-3c7","depends_on_id":"joco-ff0","type":"blocks","created_at":"2026-01-18T20:50:34.002171601Z","created_by":"vscode"}]}
{"id":"joco-58n","title":"CLI User Interface","status":"tombstone","priority":1,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:06.844038-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:18:10.366253-06:00","deleted_at":"2026-01-13T15:18:10.366253-06:00","deleted_by":"daemon","delete_reason":"delete","original_type":"epic"}
{"id":"joco-5c7","title":"D6: Curate high-quality fine-tuning dataset from extended data","description":"Apply lessons learned: data quality \u003e quantity. Curate best examples from extended dataset.\n\nProblem discovered in B2/B3/B4:\n- Extended dataset (1,276 examples) HURT classical ML\n- Too diverse (9 repos with different conventions)\n- Vocabulary explosion, distribution shift\n- Quality better than quantity\n\nSolution for fine-tuning:\nUnlike classical ML, LLMs can handle vocabulary diversity BUT still benefit from quality curation.\n\nCuration criteria:\n\n1. FORMAT QUALITY:\n   - Perfect conventional commit format\n   - Clear type (feat/fix/docs/test/ci/chore/refactor/perf/build)\n   - Concise description (\u003c50 chars preferred)\n   - No trailing periods\n   - No meta-descriptions\n\n2. DIFF QUALITY:\n   - Clear, focused changes (not 50+ files)\n   - 50-5000 char range (not tiny, not massive)\n   - Representative of real commits\n   - Diverse commit types\n\n3. SEMANTIC CLARITY:\n   - Unambiguous type (not feat + fix in one commit)\n   - Description matches diff content\n   - No vague messages ('update code', 'fix stuff')\n\n4. BALANCE:\n   - Equal representation of feat/fix (current: 315 fix, 72 feat)\n   - Target: 200 of each major type\n   - Remove over-represented types\n\nApproach:\n1. Load extended dataset (1,276 examples)\n2. Apply quality filters\n3. Balance classes (max 200 per type)\n4. Target: 800-1000 HIGH-QUALITY examples\n5. Split: 700 train, 100 validation, 100 test\n6. Save as dataset/train_curated.jsonl, dataset/val_curated.jsonl\n7. Document curation stats\n\nExpected: 800-1000 curated examples should outperform raw 1,276 examples for fine-tuning.\n\nThis feeds into D2 as better training data.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:50:01.438893587Z","created_by":"Claude Code","updated_at":"2026-01-18T21:00:09.179890036Z","closed_at":"2026-01-18T21:00:09.179890036Z","close_reason":"Successfully curated high-quality dataset: 875 examples (612 train, 131 val, 132 test) from 1,276 input examples. Applied strict quality filters (73.8% pass rate) and class balancing (max 200 per type). Created scripts/d6_curate_dataset.py, dataset/*_curated.jsonl files, and comprehensive stats in D6_CURATION_STATS.md. Logged results to EXPERIMENT_LOG.md."}
{"id":"joco-5d1","title":"Create GitHub Actions CI workflow","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T10:58:20.835288-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T10:58:43.825432-06:00","closed_at":"2026-01-15T10:58:43.825432-06:00","close_reason":"Closed"}
{"id":"joco-616","title":"Evaluate native binary size and startup time","description":"After native build is working, measure: binary size, startup time (--help), memory usage. Consider trimming: JGit → shell git, Logback → simpler logging, Gson → built-in JSON. Target: \u003c20MB binary, \u003c100ms startup.","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T20:19:23.9826-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T09:51:54.542104-06:00","closed_at":"2026-01-15T09:51:54.542104-06:00","close_reason":"Removed unused JGit dependency. Binary: 50MB → 39MB (-22%). JGit was declared but never used - code already uses shell git commands."}
{"id":"joco-6at","title":"Implement staged changes retrieval","description":"Use JGit to get staged changes (equivalent to git diff --staged). Capture diff content. Handle empty staged changes case.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:23.687461-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:06:00.384598-06:00","closed_at":"2026-01-13T16:06:00.384598-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-6at","depends_on_id":"joco-s9c","type":"parent-child","created_at":"2026-01-13T15:18:32.9318-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-6at","depends_on_id":"joco-bfo","type":"blocks","created_at":"2026-01-13T15:18:36.515735-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-6m8","title":"Create Ollama API client","description":"Implement HTTP client for localhost:11434. Create request/response models for /api/generate endpoint. Handle connection timeout (Ollama not running).","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:12.600497-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:01:55.74029-06:00","closed_at":"2026-01-13T16:01:55.74029-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-6m8","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:23.824899-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-6sh","title":"Improve user feedback and error messages","description":"Clear error messages for each failure mode. Helpful suggestions (e.g., \"Run 'ollama pull qwen2.5-coder:1.5b'\"). Color-coded output (optional, check terminal support).","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:18.971721-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:12.305262-06:00","closed_at":"2026-01-13T20:12:12.305262-06:00","close_reason":"Implemented in Wave 3","dependencies":[{"issue_id":"joco-6sh","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:24.004535-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-6sh","depends_on_id":"joco-yny","type":"blocking","created_at":"2026-01-13T15:18:27.213493-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-70n","title":"Test harness for prompt iteration","status":"closed","priority":1,"issue_type":"feature","owner":"tom@runpaste.com","created_at":"2026-01-15T11:46:49.044919-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-18T21:03:37.48746329Z","closed_at":"2026-01-18T21:03:37.48746329Z","close_reason":"Created comprehensive prompt test harness with evaluation metrics, built-in prompts, comparison reports, and documentation"}
{"id":"joco-8hs","title":"Prompt experiment: strict-format-v1 (type accuracy improvement)","description":"Results vs baseline:\n- Type distribution: Much better - uses build, docs, fix, refactor instead of defaulting to feat\n- Avg score: 65.5 vs 64.0 (+1.5)\n- Avg gen time: 5879ms vs 7634ms (-23%)\n- Completion tokens: 31.5 vs 49.8 (-37%)\n\nStill fails on:\n- Large diffs (CHANGELOG, release notes) -\u003e outputs JSON or verbose text\n- Model refusals ('I'm sorry, but I can't assist')\n- Verbose scopes (pipeline/shared instead of pipeline)","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T12:04:01.575958-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-18T20:58:36.236711396Z","closed_at":"2026-01-18T20:58:36.236711396Z","close_reason":"Closed"}
{"id":"joco-8m4","title":"A3: SVM with RBF kernel for commit type prediction","description":"Train SVM with RBF kernel for better non-linear separation.\n\nHypothesis: SVM with RBF kernel can find complex decision boundaries that separate feat/fix/refactor.\n\nAdvantages:\n- Excellent for high-dimensional spaces (TF-IDF has 1000 features)\n- RBF kernel can model complex patterns\n- Good generalization with proper regularization\n\nChallenges:\n- Slower training than logistic regression\n- Need to tune C and gamma hyperparameters\n\nApproach:\n- Use GridSearchCV to find optimal C and gamma\n- Compare to A1 (75.9%) and A2 (Random Forest)\n\nExpected: Similar or slightly better than Random Forest","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:11:18.119670175Z","created_by":"Claude Code","updated_at":"2026-01-18T20:18:39.18548633Z","closed_at":"2026-01-18T20:18:39.185488121Z"}
{"id":"joco-8m9","title":"C1: Hybrid rule-based + ML classifier","description":"Build hybrid classifier that combines rules and ML.\n\nBased on A1 findings:\n- File-based types have high precision (docs: 92%, build: 81%, test: 50%+)\n- Semantic types need ML (feat: 31%, fix: 36%)\n\nHybrid approach:\n1. Rule-based phase (file patterns):\n   - If *.md or docs/ → docs (92% precision)\n   - If package.json/pom.xml → build (81% precision)\n   - If *test* or *spec* → test (decent precision)\n   - If .github/*.yml → ci (very high precision)\n   \n2. ML phase (for ambiguous cases):\n   - Use best ML model from A2/A3/A4 for feat/fix/refactor\n   - Focus training on these types only\n\nExpected: Combine best of both worlds - \u003e85% overall accuracy","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:12:11.987147357Z","created_by":"Claude Code","updated_at":"2026-01-18T20:44:05.486298344Z","closed_at":"2026-01-18T20:44:05.486299844Z"}
{"id":"joco-9p4","title":"Set up basic logging framework","description":"Add SLF4J with simple implementation. Configure for CLI-appropriate output.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:11.714459-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:46:41.811454-06:00","closed_at":"2026-01-13T15:46:41.811454-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-9p4","depends_on_id":"joco-25d","type":"blocks","created_at":"2026-01-13T15:18:21.051725-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-9p4","depends_on_id":"joco-jps","type":"parent-child","created_at":"2026-01-13T15:18:23.39103-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-9v7","title":"Create interactive commit message editor","description":"Display generated commit message. Prompt user: [a]ccept, [e]dit, [r]egenerate, [c]ancel. Handle user input.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:17.863827-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:08:02.560946-06:00","closed_at":"2026-01-13T16:08:02.560946-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-9v7","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:23.22725-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-9v7","depends_on_id":"joco-yny","type":"blocking","created_at":"2026-01-13T15:18:26.653568-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-bfo","title":"Implement Git repository detection","description":"Check if current directory is inside a Git repository. Navigate to repository root. Provide clear error if not in Git repo.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:23.271306-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:06:00.287669-06:00","closed_at":"2026-01-13T16:06:00.287669-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-bfo","depends_on_id":"joco-s9c","type":"parent-child","created_at":"2026-01-13T15:18:32.687754-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-byk","title":"Add Ollama error handling","description":"Connection refused (Ollama not running), model not found (prompt to pull model), timeout handling, invalid response format.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:13.665224-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:01:56.027658-06:00","closed_at":"2026-01-13T16:01:56.027658-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-byk","depends_on_id":"joco-6m8","type":"depends-on","created_at":"2026-01-13T15:18:20.742434-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-byk","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:24.605643-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-c2g","title":"Configuration System","description":"Implement configuration loading from ~/.joco.config with sensible defaults. Depends on Epic 1.","status":"closed","priority":1,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:06.869804-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:51.051246-06:00","closed_at":"2026-01-13T20:12:51.051246-06:00","close_reason":"All child tasks completed"}
{"id":"joco-c2g.1","title":"Create Configuration domain model","description":"Define Config class with model, maxTokens, temperature fields. Add default values (qwen2.5-coder:1.5b, 100, 0.7). Add validation logic.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:17.261233-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:01:55.60079-06:00","closed_at":"2026-01-13T16:01:55.60079-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-c2g.1","depends_on_id":"joco-c2g","type":"parent-child","created_at":"2026-01-13T15:18:17.262367-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-c2g.2","title":"Implement configuration file reader","description":"Read from ~/.joco.config (JSON format). Handle missing file gracefully with defaults. Parse JSON using Jackson.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:19.220221-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:04:42.721011-06:00","closed_at":"2026-01-13T16:04:42.721011-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-c2g.2","depends_on_id":"joco-c2g","type":"parent-child","created_at":"2026-01-13T15:18:19.221002-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-c2g.2","depends_on_id":"joco-c2g.1","type":"blocks","created_at":"2026-01-13T15:18:19.221978-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-c2g.3","title":"Add configuration validation","description":"Validate model name format, maxTokens range (50-500), temperature range (0.0-2.0). Provide helpful error messages.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:20.906703-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:07:12.545924-06:00","closed_at":"2026-01-13T16:07:12.545924-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-c2g.3","depends_on_id":"joco-c2g","type":"parent-child","created_at":"2026-01-13T15:18:20.90758-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-c2g.3","depends_on_id":"joco-c2g.2","type":"blocks","created_at":"2026-01-13T15:18:20.908901-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-c2g.4","title":"Add configuration error handling","description":"Handle malformed JSON gracefully, missing config file (use defaults), invalid values (use defaults with warnings).","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:23.235481-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T19:50:28.273275-06:00","closed_at":"2026-01-13T19:50:28.273275-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-c2g.4","depends_on_id":"joco-c2g","type":"parent-child","created_at":"2026-01-13T15:18:23.236342-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-c2g.4","depends_on_id":"joco-c2g.2","type":"blocks","created_at":"2026-01-13T15:18:23.237728-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-c2g.4","depends_on_id":"joco-c2g.3","type":"blocks","created_at":"2026-01-13T15:18:23.23875-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-d1x","title":"B6: Re-train A3 (SVM RBF) on extended dataset","description":"Re-train A3 SVM with RBF kernel on extended dataset.\n\nOriginal A3 results (261 train, 29 val):\n- Validation accuracy: 65.5% (WORST)\n- Training accuracy: 92.3%\n- Overfitting: +26.8% (most severe)\n\nWhy A3 failed:\n- Worst overfitting of all models\n- RBF kernel overfits on small data\n- Linear problem doesn't need non-linear kernel\n\nExtended dataset might help:\n- More data for kernel to learn patterns\n- Better hyperparameter tuning with more examples\n- Reduced overfitting\n\nExpected (realistic):\n- Validation accuracy: 70-75%\n- Still likely won't beat A1/B2\n- Overfitting should reduce to \u003c18%\n\nApproach:\n1. Load extended dataset\n2. Use GridSearchCV with same parameter space\n3. Train and evaluate\n4. Compare to B2, B4, B5\n5. Final verdict on SVM viability\n6. Log results to EXPERIMENT_LOG.md\n\nLOWEST priority - SVM RBF was worst performer, unlikely to improve much.","status":"closed","priority":3,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:24:05.513271525Z","created_by":"Claude Code","updated_at":"2026-01-18T21:00:44.380142724Z","closed_at":"2026-01-18T21:00:44.380142724Z","close_reason":"Closed"}
{"id":"joco-dg1","title":"D1: Evaluate existing fine-tuned LoRA model baseline","description":"Establish baseline for existing fine-tuned model before new experiments.\n\nCurrent state:\n- Existing LoRA adapter: joco-lora-cpu/ (~4.3MB)\n- Base model: Qwen2.5-Coder-0.5B-Instruct\n- Training: 261 examples, 1 epoch\n- Method: LoRA (rank=8, alpha=16)\n\nTasks:\n1. Load existing LoRA adapter with base model\n2. Evaluate on validation set (29 examples)\n3. Evaluate on extended validation (208 examples)\n4. Run on Angular benchmark (100 examples)\n5. Compare to multi-step prompt baseline (88/100 score)\n\nMetrics to measure:\n- Format compliance (% valid conventional commits)\n- Type accuracy (% correct type)\n- Overall quality score (0-100)\n- Inference speed\n\nThis establishes baseline before D2-D5 experiments.\n\nExpected: Similar to base model (~88) or slightly better if fine-tuning helped.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:48:24.204484611Z","created_by":"Claude Code","updated_at":"2026-01-18T21:45:38.579101843Z","closed_at":"2026-01-18T21:45:38.579101843Z","close_reason":"Evaluation complete. LoRA model scored 24/100 vs 88/100 multi-step baseline. Approach abandoned - fine-tuning not viable with current setup."}
{"id":"joco-ds8","title":"Set up Maven build configuration","description":"Configure Maven Shade plugin for fat JAR. Add manifest with Main-Class entry point.","status":"closed","priority":0,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:11.176714-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:57:46.125624-06:00","closed_at":"2026-01-13T15:57:46.125624-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-ds8","depends_on_id":"joco-25d","type":"blocks","created_at":"2026-01-13T15:18:20.629582-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-ds8","depends_on_id":"joco-tu5","type":"blocks","created_at":"2026-01-13T15:18:20.778471-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-ds8","depends_on_id":"joco-jps","type":"parent-child","created_at":"2026-01-13T15:18:23.136391-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-eub","title":"Add Git diff parsing and formatting","description":"Parse diff output to identify changed files. Format diff context for LLM consumption. Limit diff size to prevent token overflow. Handle binary files gracefully.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:24.04282-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T19:51:50.988689-06:00","closed_at":"2026-01-13T19:51:50.988689-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-eub","depends_on_id":"joco-s9c","type":"parent-child","created_at":"2026-01-13T15:18:33.201668-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-eub","depends_on_id":"joco-6at","type":"blocks","created_at":"2026-01-13T15:18:36.860664-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-f5b","title":"Create basic package structure","description":"Refactor from org.example to com.joco. Create packages: config, git, ollama, cli, util.","status":"closed","priority":0,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:11.438256-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:40:52.128959-06:00","closed_at":"2026-01-13T15:40:52.128959-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-f5b","depends_on_id":"joco-jps","type":"parent-child","created_at":"2026-01-13T15:18:23.268873-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-fco","title":"Implement commit execution","description":"Execute git commit -m \"message\" with approved message. Show commit hash on success. Handle commit failures.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:18.468137-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:07:17.058304-06:00","closed_at":"2026-01-13T16:07:17.058304-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-fco","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:23.688679-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-fco","depends_on_id":"joco-9v7","type":"blocking","created_at":"2026-01-13T15:18:26.935635-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-ff0","title":"D4: Compare different base model sizes for fine-tuning","description":"Test if larger or smaller models work better for commit message generation.\n\nCurrent: Qwen2.5-Coder-0.5B-Instruct (495M params)\n\nModels to try:\n\n1. Qwen2.5-Coder-0.5B (current) - 495M params, 398MB\n   - Fastest inference\n   - Lowest memory\n   - May lack capacity\n   \n2. Qwen2.5-Coder-1.5B - 1.5B params, 986MB\n   - Better balance\n   - More capacity for patterns\n   - Still runs on 8GB RAM\n   \n3. Qwen2.5-Coder-3B - 3B params, 1.9GB\n   - Most capacity\n   - Best quality potential\n   - Near memory limit\n\nApproach:\n1. Fine-tune each model on extended dataset (1,276 examples)\n2. Use best hyperparameters from D3\n3. Same training config for fair comparison\n4. Evaluate all on:\n   - Extended validation (208 examples)\n   - Angular benchmark (100 examples)\n   - Inference speed test\n5. Compare quality vs speed trade-off\n\nMetrics:\n- Quality score (0-100)\n- Format compliance (%)\n- Type accuracy (%)\n- Inference time (ms per commit)\n- Memory usage (MB)\n\nExpected: 1.5B model likely best quality/speed trade-off.\n\nHYPOTHESIS: Larger models (1.5B, 3B) will achieve better scores but may be impractical for 8GB RAM target.","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:49:17.823655039Z","created_by":"Claude Code","updated_at":"2026-01-18T21:47:03.884390245Z","closed_at":"2026-01-18T21:47:03.884390245Z","close_reason":"Abandoned based on D1 findings: existing LoRA model scored 24/100 vs 88/100 multi-step prompt baseline. Multi-step prompting is vastly superior and production-ready. Further fine-tuning experiments not justified given 64-point gap and infrastructure constraints.","dependencies":[{"issue_id":"joco-ff0","depends_on_id":"joco-rlc","type":"blocks","created_at":"2026-01-18T20:50:26.243280145Z","created_by":"vscode"}]}
{"id":"joco-gq2","title":"Add CI badge to README","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T10:58:22.631884-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T10:58:56.478517-06:00","closed_at":"2026-01-15T10:58:56.478517-06:00","close_reason":"Closed"}
{"id":"joco-h7f","title":"Handle Git edge cases","description":"No staged changes (prompt user to stage first), initial commit (no previous commit to diff against), merge conflicts, detached HEAD state.","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:24.446451-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:12.336738-06:00","closed_at":"2026-01-13T20:12:12.336738-06:00","close_reason":"Implemented in Wave 3","dependencies":[{"issue_id":"joco-h7f","depends_on_id":"joco-s9c","type":"parent-child","created_at":"2026-01-13T15:18:33.463435-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-h7f","depends_on_id":"joco-bfo","type":"blocks","created_at":"2026-01-13T15:18:37.149439-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-h7f","depends_on_id":"joco-6at","type":"blocks","created_at":"2026-01-13T15:18:37.44945-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-htr","title":"A2: Random Forest classifier for commit type prediction","description":"Train Random Forest classifier on same features as A1.\n\nHypothesis: Random Forest can capture non-linear patterns better than Logistic Regression, especially for distinguishing feat/fix.\n\nAdvantages:\n- Better at non-linear decision boundaries\n- Can handle feature interactions\n- Built-in feature importance ranking\n- Less prone to overfitting with proper tuning\n\nApproach:\n- Use same TF-IDF features as A1\n- Train RandomForestClassifier with 100-500 trees\n- Compare accuracy to A1 baseline (75.9% validation)\n- Focus on feat/fix distinction (A1's weakness)\n\nExpected: 5-10% accuracy improvement over logistic regression","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:11:00.557848386Z","created_by":"Claude Code","updated_at":"2026-01-18T20:21:59.934669183Z","closed_at":"2026-01-18T20:21:59.934673683Z"}
{"id":"joco-jps","title":"Project Foundation \u0026 Dependencies","description":"Establish build infrastructure, dependency management, and project structure. This epic blocks all other work.","status":"closed","priority":0,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:06.844098-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:50.985431-06:00","closed_at":"2026-01-13T20:12:50.985431-06:00","close_reason":"All child tasks completed"}
{"id":"joco-k9n","title":"CLI User Interface","description":"Create intuitive command-line interface for user interaction. Depends on Epics 2, 3, and 4.","status":"closed","priority":1,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:11.687089-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:51.082634-06:00","closed_at":"2026-01-13T20:12:51.082634-06:00","close_reason":"All child tasks completed"}
{"id":"joco-kbq","title":"Add streaming response handling","description":"Handle Ollama's streaming JSON responses. Accumulate message chunks. Show progress indicator to user (optional).","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:13.110821-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:03:21.391769-06:00","closed_at":"2026-01-13T16:03:21.391769-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-kbq","depends_on_id":"joco-6m8","type":"depends-on","created_at":"2026-01-13T15:18:20.615635-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-kbq","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:24.202948-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-lz4","title":"B4: Re-train A4 (XGBoost/LightGBM) on extended dataset","description":"Re-train A4 gradient boosting models on extended dataset.\n\nOriginal A4 results (261 train, 29 val):\n- Validation accuracy: 72.4%\n- Training accuracy: 82-91%\n- Overfitting: +9.6% to +19.2%\n- Hypothesis REJECTED: performed worse than A1\n\nWhy A4 failed on small data:\n- Dataset too small (261 examples)\n- Gradient boosting needs 1000+ examples\n- Overfitting despite early stopping\n\nExtended dataset should fix this:\n- 1,276 training examples (4x more)\n- Enough data for iterative error correction\n- Early stopping should work properly now\n\nExpected improvements:\n- Validation accuracy: 78-82%\n- Training accuracy: 85-88%\n- Overfitting: \u003c6% gap\n- Should finally beat A1 baseline\n\nApproach:\n1. Load extended dataset\n2. Train both XGBoost and LightGBM\n3. Use early stopping (30 rounds)\n4. Compare to B2 (A1 on extended data)\n5. Verify if complex models work with more data\n6. Log results to EXPERIMENT_LOG.md\n\nThis tests if gradient boosting can work with adequate data.","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:23:51.163773805Z","created_by":"Claude Code","updated_at":"2026-01-18T20:30:50.776475358Z","closed_at":"2026-01-18T20:30:50.776477191Z","comments":[{"id":3,"issue_id":"joco-lz4","author":"Claude Code","text":"Experiment B4 completed with SHOCKING results: More data made models WORSE!\n\nResults:\n- B4 XGBoost: 58.2% val (vs A4: 72.4%) = -14.2% degradation\n- B4 LightGBM: 64.4% val (vs A4: 72.4%) = -8.0% degradation\n- Angular benchmark: 53-55% (vs A4: 66%) = -11-13% degradation\n- Overfitting INCREASED: 29% (vs A4: 9-19%)\n- Target NOT met: Expected 78-82%, got 64.4%\n\nWhy it failed:\n- Dataset distribution shift: 9 diverse repos with different styles\n- Vocabulary explosion: Repo-specific jargon drowned universal patterns\n- Extended dataset (1,276 examples) is MORE diverse but LESS homogeneous\n- Original dataset (261 examples) was likely from single repo or similar style\n\nKey insight: DATA QUALITY \u003e DATA QUANTITY\n- Small curated datasets can outperform large diverse ones\n- Homogeneity matters more than scale for gradient boosting\n- Distribution matching between train/test is critical\n\nDocumented in EXPERIMENT_LOG.md with full analysis.\nFiles: scripts/b4_a4_extended.py, scripts/b4_run_on_benchmarks.py","created_at":"2026-01-18T20:31:16Z"}]}
{"id":"joco-p5m","title":"Add diff size management","description":"Calculate approximate token count of diff. Truncate large diffs intelligently. Warn user if diff is truncated.","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:24.787181-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:12.36767-06:00","closed_at":"2026-01-13T20:12:12.36767-06:00","close_reason":"Implemented in Wave 3","dependencies":[{"issue_id":"joco-p5m","depends_on_id":"joco-s9c","type":"parent-child","created_at":"2026-01-13T15:18:33.715263-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-p5m","depends_on_id":"joco-eub","type":"blocks","created_at":"2026-01-13T15:18:37.716328-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-pwn","title":"Implement prompt engineering for commit messages","description":"Design system prompt for concise commit messages. Format Git diff as user prompt. Follow conventional commit style (feat, fix, chore). Keep prompt token-efficient.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:12.845039-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:01:55.886777-06:00","closed_at":"2026-01-13T16:01:55.886777-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-pwn","depends_on_id":"joco-6m8","type":"depends-on","created_at":"2026-01-13T15:18:20.4577-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-pwn","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:23.973169-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-r92","title":"B2: Re-train A1 (TF-IDF + LogReg) on extended dataset","description":"Re-train the A1 baseline (TF-IDF + Logistic Regression) on the extended dataset from B1.\n\nOriginal A1 results (261 train, 29 val):\n- Validation accuracy: 75.9%\n- Training accuracy: 87.0%\n- Overfitting: +11.1%\n\nExtended dataset (1,276 train, 208 val):\n- 412% more data\n- Better class balance\n- 9 different repos\n\nExpected improvements:\n- Validation accuracy: 80-85% (from 75.9%)\n- Reduced overfitting: \u003c8% gap (from 11.1%)\n- Better generalization across repos\n- Improved feat/fix precision\n\nApproach:\n1. Load dataset/train_extended.jsonl and dataset/validation_extended.jsonl\n2. Use same features and pipeline as A1\n3. Train and evaluate\n4. Compare to original A1 results\n5. Run on Angular benchmark\n6. Log results to EXPERIMENT_LOG.md\n\nThis is HIGH PRIORITY as A1 was the best performer on small data.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:23:19.19628861Z","created_by":"Claude Code","updated_at":"2026-01-18T20:28:01.380461923Z","closed_at":"2026-01-18T20:28:01.380463798Z","comments":[{"id":1,"issue_id":"joco-r92","author":"Claude Code","text":"B2 experiment completed. Key findings:\n\nUNEXPECTED RESULT: Extended dataset DECREASED performance\n- Validation: 75.9% → 56.7% (-19.2%)\n- Angular benchmark: 49.0%\n- Train-val gap: 24.1% → 18.5% (slight improvement)\n\nOriginal A1 was heavily overfitting (100% train, 75.9% val on 29 examples). Extended dataset reveals true generalization is much worse.\n\nConclusions:\n1. A1 is NOT the best model - original results inflated by small validation set\n2. TF-IDF features insufficient for semantic distinction (feat/fix/refactor)\n3. LLMs (88/100 score) now better than classical ML (56.7%)\n4. Hybrid approach recommended: TF-IDF for file-based types + LLM for semantic types\n\nFiles created:\n- scripts/b2_a1_extended.py\n- EXPERIMENT_LOG.md updated with full analysis\n\nSee EXPERIMENT_LOG.md for complete results and analysis.","created_at":"2026-01-18T20:28:26Z"}]}
{"id":"joco-r94","title":"A4: Gradient Boosting (XGBoost/LightGBM) for commit type prediction","description":"Train gradient boosting classifier (XGBoost or LightGBM).\n\nHypothesis: Gradient boosting can achieve best accuracy by iteratively correcting errors.\n\nAdvantages:\n- State-of-art for structured data\n- Handles feature interactions naturally\n- Built-in regularization prevents overfitting\n\nApproach:\n- Try both XGBoost and LightGBM\n- Use early stopping on validation set\n- Compare to A1/A2/A3\n\nExpected: Highest accuracy of classical ML approaches (78-82%)","status":"closed","priority":2,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:11:24.401516184Z","created_by":"Claude Code","updated_at":"2026-01-18T20:17:15.864586838Z","closed_at":"2026-01-18T20:17:15.864591422Z"}
{"id":"joco-rig","title":"Add response validation and cleanup","description":"Validate generated message is non-empty. Remove markdown formatting artifacts. Ensure proper message formatting. Truncate if too long.","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:13.946384-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T19:51:12.684629-06:00","closed_at":"2026-01-13T19:51:12.684629-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-rig","depends_on_id":"joco-kbq","type":"depends-on","created_at":"2026-01-13T15:18:21.423245-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-rig","depends_on_id":"joco-wn3","type":"parent-child","created_at":"2026-01-13T15:18:24.804532-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-rlc","title":"D2: Fine-tune Qwen2.5-Coder on extended dataset (1,276 examples)","description":"Fine-tune on extended dataset from B1 to improve performance.\n\nOriginal training:\n- 261 examples (dataset/train.jsonl)\n- 29 validation examples\n- 1 epoch\n\nExtended dataset:\n- 1,276 training examples (dataset/train_extended.jsonl)\n- 208 validation examples\n- 9 diverse repos (Vue, Electron, Babel, ESLint, Jest, Webpack, TypeScript, Redux, Next.js)\n\nTasks:\n1. Convert extended dataset to MLX format (dataset/mlx-train-extended.jsonl)\n2. Install MLX dependencies: pip install mlx mlx-lm\n3. Fine-tune using scripts/finetune-mlx.py with same hyperparameters:\n   - Base: Qwen/Qwen2.5-Coder-0.5B-Instruct\n   - LoRA rank: 8\n   - LoRA alpha: 16\n   - Learning rate: 5e-5\n   - Batch size: 1\n   - Epochs: 3 (more data = more epochs)\n4. Save adapter to joco-lora-extended/\n5. Evaluate on extended validation set\n6. Compare to D1 baseline\n7. Log results to EXPERIMENT_LOG.md\n\nExpected: 5-10% improvement from more diverse training data.\n\nHYPOTHESIS: More training examples will improve generalization across different repos and commit styles.","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:48:41.892122937Z","created_by":"Claude Code","updated_at":"2026-01-18T21:47:03.875143727Z","closed_at":"2026-01-18T21:47:03.875143727Z","close_reason":"Abandoned based on D1 findings: existing LoRA model scored 24/100 vs 88/100 multi-step prompt baseline. Multi-step prompting is vastly superior and production-ready. Further fine-tuning experiments not justified given 64-point gap and infrastructure constraints.","dependencies":[{"issue_id":"joco-rlc","depends_on_id":"joco-dg1","type":"blocks","created_at":"2026-01-18T20:50:17.728376542Z","created_by":"Claude Code"},{"issue_id":"joco-rlc","depends_on_id":"joco-5c7","type":"blocks","created_at":"2026-01-18T20:50:17.872217739Z","created_by":"vscode"}]}
{"id":"joco-s29","title":"Prompt experiment: strict-format-v1 @ temp=0.3 (best so far)","description":"Best results achieved with strict-format-v1 at temperature 0.3:\n\nMetrics (vs baseline):\n- Conventional commit rate: 70% (+10%)\n- Average score: 74.0 (+10)\n- Type distribution: build(3), fix(2), docs(1), feat(1)\n- Scope inclusion: 60%\n\nKey findings:\n- Lower temperature reduces verbose explanations\n- Still fails on large diffs (CHANGELOG, release notes)\n- 3/10 failures all from large diffs outputting JSON or explanations\n\nRecommendation: Consider truncating large diffs more aggressively","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T12:21:41.771785-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-18T21:00:41.30866307Z","closed_at":"2026-01-18T21:00:41.30866307Z","close_reason":"Closed"}
{"id":"joco-s9c","title":"Git Integration","description":"Read and parse staged changes from Git repository. Depends on Epic 1.","status":"closed","priority":1,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:18.131715-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:51.113609-06:00","closed_at":"2026-01-13T20:12:51.113609-06:00","close_reason":"All child tasks completed"}
{"id":"joco-tu5","title":"Configure Maven dependencies for Git integration","description":"Add JGit library for type-safe Git operations.","status":"closed","priority":0,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:10.907544-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T15:47:22.428487-06:00","closed_at":"2026-01-13T15:47:22.428487-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-tu5","depends_on_id":"joco-25d","type":"blocks","created_at":"2026-01-13T15:18:20.411334-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-tu5","depends_on_id":"joco-jps","type":"parent-child","created_at":"2026-01-13T15:18:22.904363-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-ue4","title":"B5: Re-train A2 (Random Forest) on extended dataset","description":"Re-train A2 Random Forest on extended dataset to test if more data helps.\n\nOriginal A2 results (261 train, 29 val):\n- Validation accuracy: 69.0%\n- Training accuracy: 93.5%\n- Overfitting: +24.5% (worst of all models)\n- 150x slower than LogReg\n\nWhy A2 failed:\n- Severe overfitting on small data\n- Random Forests struggle with sparse TF-IDF features\n- Linear problem doesn't need complex trees\n\nExtended dataset might help:\n- More data reduces overfitting\n- Better estimate of feature importance\n- More robust tree splits\n\nExpected (realistic):\n- Validation accuracy: 72-76%\n- Still likely won't beat A1/B2\n- Should reduce overfitting to \u003c15%\n\nApproach:\n1. Load extended dataset\n2. Use same hyperparameters (500 trees, max_depth=20)\n3. Train and evaluate\n4. Compare to B2 and B4\n5. Determine if Random Forest is viable with more data\n6. Log results to EXPERIMENT_LOG.md\n\nLower priority - RF unlikely to beat simpler models even with more data.","status":"closed","priority":3,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:23:57.38032064Z","created_by":"Claude Code","updated_at":"2026-01-18T21:01:15.867259482Z","closed_at":"2026-01-18T21:01:15.867259482Z","close_reason":"Completed B5 experiment: Random Forest on extended dataset achieved 60.6% validation accuracy (best among extended models). Hypothesis rejected - original 69% was inflated by small validation set. Created scripts/b5_a2_extended.py and logged results to EXPERIMENT_LOG.md."}
{"id":"joco-v8s","title":"Add command-line argument parsing","description":"Support --help flag, --version flag, --model override, --dry-run (generate but don't commit).","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:18.714869-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T19:52:12.066354-06:00","closed_at":"2026-01-13T19:52:12.066354-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-v8s","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:23.805834-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-v8s","depends_on_id":"joco-yny","type":"blocking","created_at":"2026-01-13T15:18:27.074395-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-vcs","title":"B1: Mine additional conventional commit training data from GitHub","description":"Expand training dataset by mining conventional commit repos.\n\nCurrent dataset: 290 examples (261 train, 29 val)\nTarget: 2000+ examples for better generalization\n\nRepos to mine (all use conventional commits):\n- Angular (we already have)\n- React (some use conventional)\n- Vue.js\n- Electron\n- Babel\n- ESLint\n- Jest\n- Webpack\n- TypeScript\n- Redux\n- Next.js\n\nApproach:\n1. Use GitHub API to search for conventional commit repos\n2. Filter commits with conventional format (regex: ^(feat|fix|docs|test|ci|chore|refactor|perf|build|style)(\\(.+\\))?:)\n3. Extract diff + message pairs\n4. Quality filter (same as current dataset)\n5. Balance classes (ensure good feat/fix representation)\n\nExpected impact: 5-15% accuracy improvement from larger dataset","status":"closed","priority":1,"issue_type":"task","owner":"claude-code@anthropic.com","created_at":"2026-01-18T20:12:05.663325264Z","created_by":"Claude Code","updated_at":"2026-01-18T20:21:14.412390573Z","closed_at":"2026-01-18T20:21:14.412392323Z"}
{"id":"joco-vpf","title":"Prompt experiment: baseline-v1 (60% conventional commit rate)","description":"Baseline prompt experiment results:\n- Conventional commit rate: 60%\n- Average score: 64/100\n- Issues: Model outputs JSON/verbose text instead of commit messages for large diffs\n- Type accuracy: Poor (chooses feat instead of docs/ci/build)","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T11:55:45.249274-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T12:04:09.866856-06:00","closed_at":"2026-01-15T12:04:09.866856-06:00","close_reason":"Superseded by strict-format-v1 experiment (joco-8hs)"}
{"id":"joco-wn3","title":"Ollama API Integration","description":"Integrate with local Ollama API for commit message generation. Depends on Epic 1.","status":"closed","priority":1,"issue_type":"epic","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:06.849494-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:51.017863-06:00","closed_at":"2026-01-13T20:12:51.017863-06:00","close_reason":"All child tasks completed"}
{"id":"joco-xf1","title":"Create GitHub Actions release workflow","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T10:59:42.478622-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T11:00:23.040952-06:00","closed_at":"2026-01-15T11:00:23.040952-06:00","close_reason":"Created release.yml workflow"}
{"id":"joco-yny","title":"Implement main CLI flow","description":"Orchestrate: load config → check git → get diff → call Ollama → prompt user. Add clear progress messages. Handle graceful exit on errors.","status":"closed","priority":1,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:17.603979-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T16:04:47.067055-06:00","closed_at":"2026-01-13T16:04:47.067055-06:00","close_reason":"Closed","dependencies":[{"issue_id":"joco-yny","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:23.072183-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-zf3","title":"Implement commit message editing","description":"Launch default editor (EDITOR env var or nano/vim). Write message to temp file. Read edited message back. Handle editor exit codes.","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-13T15:18:18.152169-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-13T20:12:12.274088-06:00","closed_at":"2026-01-13T20:12:12.274088-06:00","close_reason":"Implemented in Wave 3","dependencies":[{"issue_id":"joco-zf3","depends_on_id":"joco-k9n","type":"parent-child","created_at":"2026-01-13T15:18:23.418248-06:00","created_by":"tom mclaughlin"},{"issue_id":"joco-zf3","depends_on_id":"joco-9v7","type":"blocking","created_at":"2026-01-13T15:18:26.796733-06:00","created_by":"tom mclaughlin"}]}
{"id":"joco-zqb","title":"Document release process in CONTRIBUTORS.md","status":"closed","priority":2,"issue_type":"task","owner":"tom@runpaste.com","created_at":"2026-01-15T10:59:44.393087-06:00","created_by":"tom mclaughlin","updated_at":"2026-01-15T11:00:43.898782-06:00","closed_at":"2026-01-15T11:00:43.898782-06:00","close_reason":"Added release process documentation"}
